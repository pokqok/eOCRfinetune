{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ym6UK0O_4VQD",
        "outputId": "7c36d784-b173-4bd1-ec94-b6ccd405c67a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fire\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (8.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=9303d4b51410a788b60e2f13ee66578e57614af3942475f548787e3609c58053\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: lmdb, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fire, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed fire-0.7.0 lmdb-1.6.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install fire lmdb opencv-python natsort nltk torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ByOuKl8H5RjA",
        "outputId": "d4a199ea-50b7-4015-ba20-d849cd6e8814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.11/dist-packages (1.6.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (8.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install lmdb pillow torchvision nltk natsort fire\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NG5Iph0O-ALW",
        "outputId": "de06f6fa-9a12-4cae-977a-28c52aa4b9c1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.10.8)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'e:/download/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git\n",
        "%cd deep-text-recognition-benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… êµ¬ì¡° ì €ì¥ ì™„ë£Œ: directory_structure.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def write_tree_structure(root_path, output_file):\n",
        "    ignored_dirs = {'.venv', '__pycache__', '.git', '.idea', '.vscode', 'env'}\n",
        "    ignored_exts = {'.pyc', '.pkl', '.pt', '.log', '.swp'}\n",
        "\n",
        "    def is_leaf_dir(path):\n",
        "        \"\"\"í•˜ìœ„ ë””ë ‰í† ë¦¬ê°€ ì—†ëŠ” ê²½ìš° True\"\"\"\n",
        "        try:\n",
        "            for entry in os.listdir(path):\n",
        "                full_path = os.path.join(path, entry)\n",
        "                if os.path.isdir(full_path) and entry not in ignored_dirs:\n",
        "                    return False\n",
        "        except:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def walk_dir(current_path, prefix=''):\n",
        "        try:\n",
        "            entries = sorted(os.listdir(current_path))\n",
        "        except PermissionError:\n",
        "            return\n",
        "\n",
        "        entries = [e for e in entries if not (\n",
        "            e in ignored_dirs or\n",
        "            any(e.endswith(ext) for ext in ignored_exts)\n",
        "        )]\n",
        "\n",
        "        dirs = [e for e in entries if os.path.isdir(os.path.join(current_path, e))]\n",
        "        for i, name in enumerate(dirs):\n",
        "            path = os.path.join(current_path, name)\n",
        "            connector = 'â””â”€â”€ ' if i == len(dirs) - 1 else 'â”œâ”€â”€ '\n",
        "            lines.append(f\"{prefix}{connector}{name}\")\n",
        "            if not is_leaf_dir(path):\n",
        "                new_prefix = prefix + ('    ' if i == len(dirs) - 1 else 'â”‚   ')\n",
        "                walk_dir(path, new_prefix)\n",
        "\n",
        "    lines = [f\"ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°: {os.path.abspath(root_path)}\\n\"]\n",
        "    walk_dir(root_path)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(lines))\n",
        "        print(f\"âœ… êµ¬ì¡° ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "if __name__ == \"__main__\":\n",
        "    project_root = os.path.abspath('.')  # ë˜ëŠ” ì˜ˆ: 'E:/download/easyocr'\n",
        "    output_txt = \"directory_structure.txt\"\n",
        "    write_tree_structure(project_root, output_txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_PA64bN9hAy",
        "outputId": "ecca8a7f-2322-49de-9915-4fd250df883a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: e:\\download\n",
            "Written 1000 / 326670\n",
            "Written 2000 / 326670\n",
            "Written 3000 / 326670\n",
            "Written 4000 / 326670\n",
            "Written 5000 / 326670\n",
            "Written 6000 / 326670\n",
            "Written 7000 / 326670\n",
            "Written 8000 / 326670\n",
            "Written 9000 / 326670\n",
            "Written 10000 / 326670\n",
            "Written 11000 / 326670\n",
            "Written 12000 / 326670\n",
            "Written 13000 / 326670\n",
            "Written 14000 / 326670\n",
            "Written 15000 / 326670\n",
            "Written 16000 / 326670\n",
            "Written 17000 / 326670\n",
            "Written 18000 / 326670\n",
            "Written 19000 / 326670\n",
            "Written 20000 / 326670\n",
            "Written 21000 / 326670\n",
            "Written 22000 / 326670\n",
            "Written 23000 / 326670\n",
            "Written 24000 / 326670\n",
            "Written 25000 / 326670\n",
            "Written 26000 / 326670\n",
            "Written 27000 / 326670\n",
            "Written 28000 / 326670\n",
            "Written 29000 / 326670\n",
            "Written 30000 / 326670\n",
            "Written 31000 / 326670\n",
            "Written 32000 / 326670\n",
            "Written 33000 / 326670\n",
            "Written 34000 / 326670\n",
            "Written 35000 / 326670\n",
            "Written 36000 / 326670\n",
            "Written 37000 / 326670\n",
            "Written 38000 / 326670\n",
            "Written 39000 / 326670\n",
            "Written 40000 / 326670\n",
            "Written 41000 / 326670\n",
            "Written 42000 / 326670\n",
            "Written 43000 / 326670\n",
            "Written 44000 / 326670\n",
            "Written 45000 / 326670\n",
            "Written 46000 / 326670\n",
            "Written 47000 / 326670\n",
            "Written 48000 / 326670\n",
            "Written 49000 / 326670\n",
            "Written 50000 / 326670\n",
            "Written 51000 / 326670\n",
            "Written 52000 / 326670\n",
            "Written 53000 / 326670\n",
            "Written 54000 / 326670\n",
            "Written 55000 / 326670\n",
            "Written 56000 / 326670\n",
            "Written 57000 / 326670\n",
            "Written 58000 / 326670\n",
            "Written 59000 / 326670\n",
            "Written 60000 / 326670\n",
            "Written 61000 / 326670\n",
            "Written 62000 / 326670\n",
            "Written 63000 / 326670\n",
            "Written 64000 / 326670\n",
            "Written 65000 / 326670\n",
            "Written 66000 / 326670\n",
            "Written 67000 / 326670\n",
            "Written 68000 / 326670\n",
            "Written 69000 / 326670\n",
            "Written 70000 / 326670\n",
            "Written 71000 / 326670\n",
            "Written 72000 / 326670\n",
            "Written 73000 / 326670\n",
            "Written 74000 / 326670\n",
            "Written 75000 / 326670\n",
            "Written 76000 / 326670\n",
            "Written 77000 / 326670\n",
            "Written 78000 / 326670\n",
            "Written 79000 / 326670\n",
            "Written 80000 / 326670\n",
            "Written 81000 / 326670\n",
            "Written 82000 / 326670\n",
            "Written 83000 / 326670\n",
            "Written 84000 / 326670\n",
            "Written 85000 / 326670\n",
            "Written 86000 / 326670\n",
            "Written 87000 / 326670\n",
            "Written 88000 / 326670\n",
            "Written 89000 / 326670\n",
            "Written 90000 / 326670\n",
            "Written 91000 / 326670\n",
            "Written 92000 / 326670\n",
            "Written 93000 / 326670\n",
            "Written 94000 / 326670\n",
            "Written 95000 / 326670\n",
            "Written 96000 / 326670\n",
            "Written 97000 / 326670\n",
            "Written 98000 / 326670\n",
            "Written 99000 / 326670\n",
            "Written 100000 / 326670\n",
            "Written 101000 / 326670\n",
            "Written 102000 / 326670\n",
            "Written 103000 / 326670\n",
            "Written 104000 / 326670\n",
            "Written 105000 / 326670\n",
            "Written 106000 / 326670\n",
            "Written 107000 / 326670\n",
            "Written 108000 / 326670\n",
            "Written 109000 / 326670\n",
            "Written 110000 / 326670\n",
            "Written 111000 / 326670\n",
            "Written 112000 / 326670\n",
            "Written 113000 / 326670\n",
            "Written 114000 / 326670\n",
            "Written 115000 / 326670\n",
            "Written 116000 / 326670\n",
            "Written 117000 / 326670\n",
            "Written 118000 / 326670\n",
            "Written 119000 / 326670\n",
            "Written 120000 / 326670\n",
            "Written 121000 / 326670\n",
            "Written 122000 / 326670\n",
            "Written 123000 / 326670\n",
            "Written 124000 / 326670\n",
            "Written 125000 / 326670\n",
            "Written 126000 / 326670\n",
            "Written 127000 / 326670\n",
            "Written 128000 / 326670\n",
            "Written 129000 / 326670\n",
            "Written 130000 / 326670\n",
            "Written 131000 / 326670\n",
            "Written 132000 / 326670\n",
            "Written 133000 / 326670\n",
            "Written 134000 / 326670\n",
            "Written 135000 / 326670\n",
            "Written 136000 / 326670\n",
            "Written 137000 / 326670\n",
            "Written 138000 / 326670\n",
            "Written 139000 / 326670\n",
            "Written 140000 / 326670\n",
            "Written 141000 / 326670\n",
            "Written 142000 / 326670\n",
            "Written 143000 / 326670\n",
            "Written 144000 / 326670\n",
            "Written 145000 / 326670\n",
            "Written 146000 / 326670\n",
            "Written 147000 / 326670\n",
            "Written 148000 / 326670\n",
            "Written 149000 / 326670\n",
            "Written 150000 / 326670\n",
            "Written 151000 / 326670\n",
            "Written 152000 / 326670\n",
            "Written 153000 / 326670\n",
            "Written 154000 / 326670\n",
            "Written 155000 / 326670\n",
            "Written 156000 / 326670\n",
            "Written 157000 / 326670\n",
            "Written 158000 / 326670\n",
            "Written 159000 / 326670\n",
            "Written 160000 / 326670\n",
            "Written 161000 / 326670\n",
            "Written 162000 / 326670\n",
            "Written 163000 / 326670\n",
            "Written 164000 / 326670\n",
            "Written 165000 / 326670\n",
            "Written 166000 / 326670\n",
            "Written 167000 / 326670\n",
            "Written 168000 / 326670\n",
            "Written 169000 / 326670\n",
            "Written 170000 / 326670\n",
            "Written 171000 / 326670\n",
            "Written 172000 / 326670\n",
            "Written 173000 / 326670\n",
            "Written 174000 / 326670\n",
            "Written 175000 / 326670\n",
            "Written 176000 / 326670\n",
            "Written 177000 / 326670\n",
            "Written 178000 / 326670\n",
            "Written 179000 / 326670\n",
            "Written 180000 / 326670\n",
            "Written 181000 / 326670\n",
            "Written 182000 / 326670\n",
            "Written 183000 / 326670\n",
            "Written 184000 / 326670\n",
            "Written 185000 / 326670\n",
            "Written 186000 / 326670\n",
            "Written 187000 / 326670\n",
            "Written 188000 / 326670\n",
            "Written 189000 / 326670\n",
            "Written 190000 / 326670\n",
            "Written 191000 / 326670\n",
            "Written 192000 / 326670\n",
            "Written 193000 / 326670\n",
            "Written 194000 / 326670\n",
            "Written 195000 / 326670\n",
            "Written 196000 / 326670\n",
            "Written 197000 / 326670\n",
            "Written 198000 / 326670\n",
            "Written 199000 / 326670\n",
            "Written 200000 / 326670\n",
            "Written 201000 / 326670\n",
            "Written 202000 / 326670\n",
            "Written 203000 / 326670\n",
            "Written 204000 / 326670\n",
            "Written 205000 / 326670\n",
            "Written 206000 / 326670\n",
            "Written 207000 / 326670\n",
            "Written 208000 / 326670\n",
            "Written 209000 / 326670\n",
            "Written 210000 / 326670\n",
            "Written 211000 / 326670\n",
            "Written 212000 / 326670\n",
            "Written 213000 / 326670\n",
            "Written 214000 / 326670\n",
            "Written 215000 / 326670\n",
            "Written 216000 / 326670\n",
            "Written 217000 / 326670\n",
            "Written 218000 / 326670\n",
            "Written 219000 / 326670\n",
            "Written 220000 / 326670\n",
            "Written 221000 / 326670\n",
            "Written 222000 / 326670\n",
            "Written 223000 / 326670\n",
            "Written 224000 / 326670\n",
            "Written 225000 / 326670\n",
            "Written 226000 / 326670\n",
            "Written 227000 / 326670\n",
            "Written 228000 / 326670\n",
            "Written 229000 / 326670\n",
            "Written 230000 / 326670\n",
            "Written 231000 / 326670\n",
            "Written 232000 / 326670\n",
            "Written 233000 / 326670\n",
            "Written 234000 / 326670\n",
            "Written 235000 / 326670\n",
            "Written 236000 / 326670\n",
            "Written 237000 / 326670\n",
            "Written 238000 / 326670\n",
            "Written 239000 / 326670\n",
            "Written 240000 / 326670\n",
            "Written 241000 / 326670\n",
            "Written 242000 / 326670\n",
            "Written 243000 / 326670\n",
            "Written 244000 / 326670\n",
            "Written 245000 / 326670\n",
            "Written 246000 / 326670\n",
            "Written 247000 / 326670\n",
            "Written 248000 / 326670\n",
            "Written 249000 / 326670\n",
            "Written 250000 / 326670\n",
            "Written 251000 / 326670\n",
            "Written 252000 / 326670\n",
            "Written 253000 / 326670\n",
            "Written 254000 / 326670\n",
            "Written 255000 / 326670\n",
            "Written 256000 / 326670\n",
            "Written 257000 / 326670\n",
            "Written 258000 / 326670\n",
            "Written 259000 / 326670\n",
            "Written 260000 / 326670\n",
            "Written 261000 / 326670\n",
            "Written 262000 / 326670\n",
            "Written 263000 / 326670\n",
            "Written 264000 / 326670\n",
            "Written 265000 / 326670\n",
            "Written 266000 / 326670\n",
            "Written 267000 / 326670\n",
            "Written 268000 / 326670\n",
            "Written 269000 / 326670\n",
            "Written 270000 / 326670\n",
            "Written 271000 / 326670\n",
            "Written 272000 / 326670\n",
            "Written 273000 / 326670\n",
            "Written 274000 / 326670\n",
            "Written 275000 / 326670\n",
            "Written 276000 / 326670\n",
            "Written 277000 / 326670\n",
            "Written 278000 / 326670\n",
            "Written 279000 / 326670\n",
            "Written 280000 / 326670\n",
            "Written 281000 / 326670\n",
            "Written 282000 / 326670\n",
            "Written 283000 / 326670\n",
            "Written 284000 / 326670\n",
            "Written 285000 / 326670\n",
            "Written 286000 / 326670\n",
            "Written 287000 / 326670\n",
            "Written 288000 / 326670\n",
            "Written 289000 / 326670\n",
            "Written 290000 / 326670\n",
            "Written 291000 / 326670\n",
            "Written 292000 / 326670\n",
            "Written 293000 / 326670\n",
            "Written 294000 / 326670\n",
            "Written 295000 / 326670\n",
            "Written 296000 / 326670\n",
            "Written 297000 / 326670\n",
            "Written 298000 / 326670\n",
            "Written 299000 / 326670\n",
            "Written 300000 / 326670\n",
            "Written 301000 / 326670\n",
            "Written 302000 / 326670\n",
            "Written 303000 / 326670\n",
            "Written 304000 / 326670\n",
            "Written 305000 / 326670\n",
            "Written 306000 / 326670\n",
            "Written 307000 / 326670\n",
            "Written 308000 / 326670\n",
            "Written 309000 / 326670\n",
            "Written 310000 / 326670\n",
            "Written 311000 / 326670\n",
            "Written 312000 / 326670\n",
            "Written 313000 / 326670\n",
            "Written 314000 / 326670\n",
            "Written 315000 / 326670\n",
            "Written 316000 / 326670\n",
            "Written 317000 / 326670\n",
            "Written 318000 / 326670\n",
            "Written 319000 / 326670\n",
            "Written 320000 / 326670\n",
            "Written 321000 / 326670\n",
            "Written 322000 / 326670\n",
            "Written 323000 / 326670\n",
            "Written 324000 / 326670\n",
            "Written 325000 / 326670\n",
            "Written 326000 / 326670\n",
            "Created dataset with 326670 samples\n",
            "Written 1000 / 36297\n",
            "Written 2000 / 36297\n",
            "Written 3000 / 36297\n",
            "Written 4000 / 36297\n",
            "Written 5000 / 36297\n",
            "Written 6000 / 36297\n",
            "Written 7000 / 36297\n",
            "Written 8000 / 36297\n",
            "Written 9000 / 36297\n",
            "Written 10000 / 36297\n",
            "Written 11000 / 36297\n",
            "Written 12000 / 36297\n",
            "Written 13000 / 36297\n",
            "Written 14000 / 36297\n",
            "Written 15000 / 36297\n",
            "Written 16000 / 36297\n",
            "Written 17000 / 36297\n",
            "Written 18000 / 36297\n",
            "Written 19000 / 36297\n",
            "Written 20000 / 36297\n",
            "Written 21000 / 36297\n",
            "Written 22000 / 36297\n",
            "Written 23000 / 36297\n",
            "Written 24000 / 36297\n",
            "Written 25000 / 36297\n",
            "Written 26000 / 36297\n",
            "Written 27000 / 36297\n",
            "Written 28000 / 36297\n",
            "Written 29000 / 36297\n",
            "Written 30000 / 36297\n",
            "Written 31000 / 36297\n",
            "Written 32000 / 36297\n",
            "Written 33000 / 36297\n",
            "Written 34000 / 36297\n",
            "Written 35000 / 36297\n",
            "Written 36000 / 36297\n",
            "Created dataset with 36297 samples\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ê³ , í•„ìš”í•˜ë‹¤ë©´ ë³€ê²½í•©ë‹ˆë‹¤.\n",
        "current_dir = os.getcwd()\n",
        "print(f\"Current working directory: {current_dir}\")\n",
        "\n",
        "# ë§Œì•½ í˜„ì¬ ë””ë ‰í† ë¦¬ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥´ë‹¤ë©´, ë‹¤ìŒ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ê²½ë¡œë¥¼ ë§ì¶°ì£¼ì„¸ìš”.\n",
        "# os.chdir('E:\\\\download\\\\deep-text-recognition-benchmark')\n",
        "# print(f\"Changed working directory to: {os.getcwd()}\")\n",
        "\n",
        "\n",
        "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs('./data_lmdb/train/basic', exist_ok=True)\n",
        "os.makedirs('./data_lmdb/validation/basic', exist_ok=True)\n",
        "\n",
        "# train LMDB ì¬ìƒì„±\n",
        "!python3 E:\\download\\deep-text-recognition-benchmark\\create_lmdb_dataset.py \\\n",
        "  --inputPath E:\\download\\final_dataset\\train_data \\\n",
        "  --gtFile E:\\download\\final_dataset\\train_data\\labels.txt \\\n",
        "  --outputPath ./data_lmdb/train/basic\n",
        "\n",
        "# valid LMDB ì¬ìƒì„±\n",
        "!python3 E:\\download\\deep-text-recognition-benchmark\\create_lmdb_dataset.py \\\n",
        "  --inputPath E:\\download\\final_dataset\\valid_data \\\n",
        "  --gtFile E:\\download\\final_dataset\\valid_data\\labels.txt \\\n",
        "  --outputPath ./data_lmdb/validation/basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì„±ê³µ! 'korean_char_1008.txt' íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ì´ ë¬¸ì ìˆ˜: 1008\n",
            "ìƒì„±ëœ ë¬¸ìì—´ ë¯¸ë¦¬ë³´ê¸°:  !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcde...\n"
          ]
        }
      ],
      "source": [
        "import ast # ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "input_filename = 'chars.txt'\n",
        "output_filename = 'korean_char_1008.txt'\n",
        "\n",
        "try:\n",
        "    # 1. í˜„ì¬ ì˜ëª»ëœ í˜•ì‹ì˜ íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.\n",
        "    with open(input_filename, 'r', encoding='utf-8') as f:\n",
        "        # íŒŒì¼ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.\n",
        "        content = f.read().replace('\\n', '')\n",
        "\n",
        "    # 2. ì½ì–´ì˜¨ ë¬¸ìì—´ì„ ì‹¤ì œ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "    char_list = ast.literal_eval(content)\n",
        "\n",
        "    # 3. (ì¤‘ìš”) ë¦¬ìŠ¤íŠ¸ì˜ ì²« ìš”ì†Œì¸ '[blank]'ë¥¼ ì œê±°í•©ë‹ˆë‹¤.\n",
        "    # [blank] í† í°ì€ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ìë™ ì¶”ê°€í•˜ë¯€ë¡œ,\n",
        "    # ë¬¸ì ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì—ëŠ” í¬í•¨ì‹œí‚¤ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.\n",
        "    if char_list and char_list[0] == '[blank]':\n",
        "        char_list = char_list[1:]\n",
        "\n",
        "    # 4. ë¬¸ì ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ìˆœìˆ˜í•œ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
        "    correct_string = \"\".join(char_list)\n",
        "\n",
        "    # 5. ë³€í™˜ëœ ë¬¸ìì—´ì„ ìƒˆë¡œìš´ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(correct_string)\n",
        "\n",
        "    print(f\"âœ… ì„±ê³µ! '{output_filename}' íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"ì´ ë¬¸ì ìˆ˜: {len(correct_string)}\")\n",
        "    print(f\"ìƒì„±ëœ ë¬¸ìì—´ ë¯¸ë¦¬ë³´ê¸°: {correct_string[:70]}...\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ ì˜¤ë¥˜: '{input_filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ì˜¤ë¥˜: íŒŒì¼ ë³€í™˜ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. - {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "dataset_root: ./data_lmdb/train/basic\n",
            "opt.select_data: ['basic']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    ./data_lmdb/train/basic\t dataset: basic\n",
            "sub-directory:\t/.\t num samples: 326670\n",
            "num total samples of basic: 326670 x 1.0 (total_data_usage_ratio) = 326670\n",
            "num samples of basic per batch: 16 x 1.0 (batch_ratio) = 16\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 16 = 16\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    ./data_lmdb/validation/basic\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 36297\n",
            "--------------------------------------------------------------------------------\n",
            "model input parameters 64 100 20 1 256 256 23 25 TPS ResNet BiLSTM CTC\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
            "loading pretrained model from E:/download/saved_models/korean_g2.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Traceback (most recent call last):\n",
            "  File \"e:\\download\\deep-text-recognition-benchmark\\train.py\", line 318, in <module>\n",
            "    train(opt)\n",
            "  File \"e:\\download\\deep-text-recognition-benchmark\\train.py\", line 84, in train\n",
            "    model.load_state_dict(torch.load(opt.saved_model, map_location=torch.device('cpu')), strict=False)\n",
            "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py\", line 2593, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for DataParallel:\n",
            "\tsize mismatch for module.Prediction.weight: copying a param with shape torch.Size([1009, 256]) from checkpoint, the shape in current model is torch.Size([23, 256]).\n",
            "\tsize mismatch for module.Prediction.bias: copying a param with shape torch.Size([1009]) from checkpoint, the shape in current model is torch.Size([23]).\n"
          ]
        }
      ],
      "source": [
        "!python3 ./deep-text-recognition-benchmark/train.py --train_data ./data_lmdb/train/basic --valid_data ./data_lmdb/validation/basic --select_data basic --batch_ratio 1 --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction CTC --saved_model \"E:/download/saved_models/korean_g2.pth\" --FT --imgH 64 --imgW 100 --input_channel 1 --output_channel 256 --hidden_size 256 --data_filtering_off --batch_size 16 --workers 0 --num_iter 1000 --valInterval 100 --lr 0.001 --character E:/download/korean_char_1008.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ATXSA07AEDx",
        "outputId": "f6932dbe-cc5a-4bed-f518-5a9983c02264"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "> was unexpected at this time.\n"
          ]
        }
      ],
      "source": [
        "!python3 ./deep-text-recognition-benchmark/train.py \\\n",
        "--train_data ./data_lmdb/train/basic \\\n",
        "--valid_data ./data_lmdb/validation/basic \\\n",
        "--select_data basic \\\n",
        "--batch_ratio 1 \\\n",
        "--Transformation TPS \\\n",
        "--FeatureExtraction ResNet \\\n",
        "--SequenceModeling BiLSTM \\\n",
        "--Prediction CTC \\\n",
        "--imgH 64 \\\n",
        "--imgW 100 \\\n",
        "--input_channel 1 \\\n",
        "--output_channel 256 \\\n",
        "--hidden_size 256 \\\n",
        "--data_filtering_off \\\n",
        "--batch_size 16 \\\n",
        "--workers 0 \\\n",
        "--num_iter 1000 \\\n",
        "--valInterval 100 \\\n",
        "--saved_model \"E:/download/saved_models/korean_g2.pth\" \\\n",
        "--FT \\\n",
        "--lr 0.001 \\\n",
        "--character=\"!\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ê°€ê°ê°„ê°‡ê°ˆê°ê°‘ê°’ê°•ê°–ê°™ê°šê°›ê°œê°ê±€ê±°ê±±ê±´ê±·ê±¸ê²€ê²ê²ƒê²‰ê²Œê²¨ê²©ê²ªê²¬ê²°ê²¹ê²½ê³ê³„ê³ ê³¡ê³¤ê³§ê³¨ê³°ê³±ê³³ê³µê³¼ê´€ê´‘ê´œê´´êµ‰êµêµ¬êµ­êµ°êµ³êµ´êµµêµ¶êµ½ê¶ê¶Œê·€ê·œê· ê·¸ê·¹ê·¼ê¸€ê¸ê¸ˆê¸‰ê¸‹ê¸ê¸°ê¸´ê¸¸ê¹€ê¹…ê¹Šê¹Œê¹ê¹ê¹”ê¹œê¹ê¹¥ê¹¨êº¼êº¾ê»ê»ê»‘ê»˜ê»´ê¼¬ê¼­ê¼´ê¼¼ê¼½ê½‚ê½ƒê½‰ê½¤ê¾¸ê¿€ê¿ˆë€Œë„ëˆëŠëŒë“ë”ë—ëë¼ë‚Œë‚˜ë‚™ë‚šë‚œë‚ ë‚¡ë‚¨ë‚©ë‚«ë‚­ë‚®ë‚¯ë‚±ë‚³ë‚´ëƒ„ëƒ‰ëƒëƒ¥ë„ˆë„‰ë„ë„“ë„˜ë„£ë„¤ë„¥ë„·ë…€ë…ë…„ë…ë…•ë…¸ë…¹ë…¼ë†€ë†ˆë†ë†’ë†“ë†”ë‡Œë‡¨ëˆ„ëˆˆëˆ•ë‰˜ë‰´ëŠ„ëŠëŠ‘ëŠ”ëŠ˜ëŠ™ëŠ¥ëŠ¦ëŠ¬ë‹ˆë‹ë‹˜ë‹¤ë‹¥ë‹¦ë‹¨ë‹«ë‹¬ë‹­ë‹®ë‹´ë‹µë‹·ë‹¹ë‹¿ëŒ€ëŒëŒë”ë•ë˜ëœë¤ë¥ë§ë©ë®ë°ë¸ë„ë…ëˆëŒë•ë™ë¼ë˜ëœë‘ë‘‘ë‘˜ë‘ ë‘¡ë‘¥ë’¤ë’·ë“œë“ë“ ë“£ë“¤ë“¬ë“­ë“¯ë“±ë””ë”©ë”ªë”°ë”±ë”´ë”¸ë•€ë•…ë•Œë•œë– ë–¡ë–¤ë–¨ë–»ë–¼ë˜ë˜‘ëšœëš«ëš±ë›°ëœ¨ëœ©ëœ¯ëœ°ëœ»ë„ë¼ë½ë€ëŒëë‘ë—ë˜ëœë¨ë«ëµëŸ‰ëŸ¬ëŸ­ëŸ°ëŸ´ëŸ¼ëŸ½ëŸ¿ë ë ‡ë ˆë ‰ë Œë ¤ë ¥ë ¨ë ¬ë µë ¹ë¡€ë¡œë¡ë¡ ë¡¬ë¡­ë¡¯ë£Œë£¨ë£©ë£¹ë£»ë¤„ë¥˜ë¥™ë¥ ë¥­ë¥´ë¥¸ë¦„ë¦‡ë¦ë¦¬ë¦­ë¦°ë¦¼ë¦½ë¦¿ë§ˆë§‰ë§Œë§ë§ë§‘ë§˜ë§™ë§›ë§ë§ë§¡ë§£ë§¤ë§¥ë§¨ë§µë§ºë¨¸ë¨¹ë¨¼ë©€ë©ˆë©‹ë©ë©ë©”ë©˜ë©©ë©°ë©´ë©¸ëª…ëª‡ëª¨ëª©ëª°ëª¸ëª¹ëª»ëª½ë¬˜ë¬´ë¬µë¬¶ë¬¸ë¬»ë¬¼ë­„ë­‡ë­ë­£ë¯€ë¯¸ë¯¼ë¯¿ë°€ë°‰ë°Œë°ë°‘ë°”ë°•ë°–ë°˜ë°›ë°œë°ë°Ÿë°¤ë°¥ë°©ë°­ë°°ë°±ë±€ë±ƒë±‰ë²„ë²ˆë²Œë²”ë²•ë²—ë² ë²¤ë²¼ë²½ë³€ë³„ë³ë³‘ë³•ë³´ë³µë³¶ë³¸ë³¼ë´„ë´‡ë´‰ëµˆëµ™ë¶€ë¶ë¶„ë¶ˆë¶‰ë¶ë¶“ë¶•ë¶™ë·°ë¸Œë¸”ë¹„ë¹Œë¹—ë¹šë¹›ë¹ ë¹¨ë¹µë¹¼ëº¨ë»ë»”ë»—ë¼ˆë½‘ë¿Œë¿ì˜ì¨ì‚¬ì‚­ì‚°ì‚´ì‚¶ì‚¼ìƒìƒˆìƒ‰ìƒŒìƒì„œì„ì„ì„ ì„¤ì„¬ì„­ì„¯ì„±ì„¸ì„¼ì…ˆì…‹ì…˜ì†Œì†ì†ì†”ì†œì†Ÿì†¡ì†¥ì‡„ì‡ ì‡¼ìˆ˜ìˆ™ìˆœìˆ ìˆ¨ìˆ«ìˆ²ì‰¬ì‰½ìŠˆìŠ¤ìŠ¨ìŠ¬ìŠ´ìŠµìŠ·ìŠ¹ì‹œì‹ì‹ ì‹£ì‹¤ì‹«ì‹¬ì‹­ì‹±ì‹¶ì‹¸ì‹¹ìŒ€ìŒìŒ“ì¨ì©ì°ì¹ì„ì˜ìŸì‘¤ì“°ì“¸ì”€ì”Œì”¨ì”©ì”¬ì”¹ì”»ì•„ì•…ì•ˆì•‰ì•Šì•Œì•“ì•”ì••ì•—ì•™ì•ì• ì•¡ì•¼ì•½ì–‡ì–‘ì–—ì–˜ì–´ì–µì–¸ì–¹ì–»ì–¼ì—„ì—…ì—†ì—‡ì—‰ì—Œì—ì—ì—”ì—˜ì—¬ì—­ì—°ì—´ì—·ì—¼ì—½ì—¿ì˜ì˜†ì˜ˆì˜›ì˜¤ì˜¥ì˜¨ì˜¬ì˜®ì˜³ì˜·ì™€ì™„ì™•ì™œì™ ì™¸ì™¼ìš”ìš•ìš©ìš°ìš±ìš´ìš¸ì›€ì›ƒì›…ì›Œì›ì›”ì›¨ì›¬ìœ„ìœ—ìœ ìœ¡ìœ¨ìœ¼ìœ½ì€ì„ìŒì‘ì˜ì´ìµì¸ì¼ì½ìƒì„ì…ì‡ìˆìŠììì‘ì”ì–ì˜ì ì¡ì¥ì¦ì¬ìŸì €ì ì „ì ˆì Šì ì ‘ì “ì •ì –ì œì  ì ¯ì ¸ì¡°ì¡±ì¡´ì¡¸ì¢€ì¢ì¢…ì¢‹ì¢Œì£„ì£¼ì£½ì¤€ì¤„ì¤Œì¤ì¤‘ì¥ì¦ˆì¦‰ì¦Œì¦ì¦˜ì¦ì§€ì§ì§„ì§ˆì§ì§‘ì§“ì§•ì§™ì§šì§œì§ì§§ì§¸ì¨Œì©Œì©ì©ìª½ì«“ì­ˆì­‰ì°Œì°ì°¢ì°¨ì°©ì°¬ì°®ì°°ì°¸ì°½ì°¾ì±„ì±…ì±”ì±™ì²˜ì²™ì²œì² ì²«ì²­ì²´ì³ì´ˆì´‰ì´Œì´ì´¬ìµœì¶”ì¶•ì¶˜ì¶œì¶¤ì¶¥ì¶§ì¶©ì·¨ì¸ ì¸¡ì¸°ì¸µì¹˜ì¹™ì¹œì¹ ì¹¨ì¹­ì¹´ì¹¸ì¹¼ìºìº ì»¤ì»¨ì»¬ì»´ì»µì»·ì¼“ì¼œì½”ì½œì½¤ì½©ì¾Œì¿ í€´í¬í°í´í¼í‚¤í‚¬íƒ€íƒíƒ„íƒˆíƒ‘íƒ“íƒ•íƒœíƒíƒ¤í„°í„±í„¸í……í…Œí…í…”í…œí† í†¤í†±í†µí‡´íˆ¬íˆ¼í‰íŠ€íŠœíŠ¸íŠ¹íŠ¼íŠ¿í‹€í‹ˆí‹°í‹±íŒ€íŒ…íŒŒíŒíŒíŒ”íŒ¨íŒ©íŒ¬í¼í½í˜í´í¸í¼í‰íí¬í­í‘œí‘¸í‘¹í’€í’ˆí’í“¨í”„í”Œí””í”¼í”½í•„í•í•‘í•˜í•™í•œí• í•¨í•©í•­í•´í•µí•¸í–„í–‡í–‰í–¥í—ˆí—Œí—˜í—¤í—¬í˜€í˜„í˜ˆí˜‘í˜•í˜œí˜¸í˜¹í˜¼í™€í™í™”í™•í™˜í™œí™©íšŒíšíšŸíš¨í›„í›ˆí›Œí›”í›¨íœ˜íœ´í‰íí‘í”í˜í™í¡í¥í©í¬í°íˆí˜\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "iWgcj9m-JDIE",
        "outputId": "467e2224-9a3b-4870-9010-a264aad885ee"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-3689481335.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data_lmdb/train/basic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num-samples'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of samples: {nSamples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
          ]
        }
      ],
      "source": [
        "import lmdb\n",
        "# Check if the LMDB file can be opened\n",
        "env = lmdb.open('./data_lmdb/train/basic')\n",
        "with env.begin(write=False) as txn:\n",
        "    nSamples = int(txn.get('num-samples'.encode()))\n",
        "    print(f\"Number of samples: {nSamples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9SqMbc9BjiY"
      },
      "outputs": [],
      "source": [
        "!ls ./data_lmdb/train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppli6Qh6id7B",
        "outputId": "61f301cc-fd08-4193-9d2d-1574aed8c371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'/content/deep-text-recognition-benchmark/data/gt_train.txt' íŒŒì¼ì˜ í™•ì¥ìë¥¼ .PNGë¡œ ì„±ê³µì ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n",
            "'/content/deep-text-recognition-benchmark/data/gt_valid.txt' íŒŒì¼ì˜ í™•ì¥ìë¥¼ .PNGë¡œ ì„±ê³µì ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ì •í™•í•œ ì „ì²´ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •\n",
        "file_paths = [\n",
        "    '/content/deep-text-recognition-benchmark/data/gt_train.txt',\n",
        "    '/content/deep-text-recognition-benchmark/data/gt_valid.txt'\n",
        "]\n",
        "\n",
        "def change_extension_case(file_path):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ì„ ì½ì–´ '.png'ë¥¼ '.PNG'ë¡œ ë³€ê²½í•œ ë’¤ ë‹¤ì‹œ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # íŒŒì¼ ì½ê¸°\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # '.png'ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë³€ê²½\n",
        "        if '.png' in content:\n",
        "            new_content = content.replace('.png', '.PNG')\n",
        "\n",
        "            # ë³€ê²½ëœ ë‚´ìš©ìœ¼ë¡œ íŒŒì¼ ë‹¤ì‹œ ì“°ê¸°\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(new_content)\n",
        "            print(f\"'{file_path}' íŒŒì¼ì˜ í™•ì¥ìë¥¼ .PNGë¡œ ì„±ê³µì ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\")\n",
        "        else:\n",
        "            print(f\"'{file_path}' íŒŒì¼ì— ë³€ê²½í•  '.png' í™•ì¥ìê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    except Exception as e:\n",
        "        print(f\"'{file_path}' íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "\n",
        "# ëª©ë¡ì— ìˆëŠ” ê° íŒŒì¼ì— ëŒ€í•´ í•¨ìˆ˜ ì‹¤í–‰\n",
        "for path in file_paths:\n",
        "    change_extension_case(path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uyUGMugOkd1",
        "outputId": "cad57a21-59b9-4122-9043-46b1e5c9c515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ëª¨ë“  ê³ ìœ  ê¸€ìë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.\n",
            "--------------------------------------------------\n",
            "ìƒì„±ëœ character ë¬¸ìì—´:\n",
            " ()-.0123456789:mê°€ê°ê°™ê°œê²Œê²¼ê³„ê³ ê³¼ê´‘êµ¬ê· ê¸ˆê¸°ê¸¸ê¹€ê¹Œë‚™ë‚©ë…„ë†ëŠ”ë‹¤ë‹¬ëŒ€ë•ë„ë™ë“±ë•Œë˜ë¡œë¡ë¥¼ë§Œë©´ëª…ë¬¸ë°›ë°©ë°°ë°±ë²ˆë³´ë³¸ë¶€ë¶ì‚¬ì‚°ì‚¼ì„œì„±ìŠ¤ìŠ¹ì‹œì‹ ìŒì•„ì•™ì•¡ì•½ì–´ì—…ì—ì—­ì˜ˆì˜¤ì™€ì™„ìš©ìš°ì›ì›”ìœ„ìœ¼ì€ì„ì˜ì´ì¸ì¼ì„ìì „ì •ì œì¡°ì£¼ì£½ì¤‘ì¦ì§€ì§„ì°¨ì°½ì²œì² ì²´ìµœì¹´íƒœí„°íŠ¸íŒŒíŒ”í•˜í•œí•¨í•©í•´í˜„í˜‘í˜¸í™”í›ˆ\n",
            "--------------------------------------------------\n",
            "ğŸ‘‡ ì•„ë˜ì˜ --character ì˜µì…˜ì„ ë³µì‚¬í•˜ì—¬ í•™ìŠµ ëª…ë ¹ì–´ì— ì¶”ê°€í•˜ì„¸ìš”.\n",
            "--character=\" ()-.0123456789:mê°€ê°ê°™ê°œê²Œê²¼ê³„ê³ ê³¼ê´‘êµ¬ê· ê¸ˆê¸°ê¸¸ê¹€ê¹Œë‚™ë‚©ë…„ë†ëŠ”ë‹¤ë‹¬ëŒ€ë•ë„ë™ë“±ë•Œë˜ë¡œë¡ë¥¼ë§Œë©´ëª…ë¬¸ë°›ë°©ë°°ë°±ë²ˆë³´ë³¸ë¶€ë¶ì‚¬ì‚°ì‚¼ì„œì„±ìŠ¤ìŠ¹ì‹œì‹ ìŒì•„ì•™ì•¡ì•½ì–´ì—…ì—ì—­ì˜ˆì˜¤ì™€ì™„ìš©ìš°ì›ì›”ìœ„ìœ¼ì€ì„ì˜ì´ì¸ì¼ì„ìì „ì •ì œì¡°ì£¼ì£½ì¤‘ì¦ì§€ì§„ì°¨ì°½ì²œì² ì²´ìµœì¹´íƒœí„°íŠ¸íŒŒíŒ”í•˜í•œí•¨í•©í•´í˜„í˜‘í˜¸í™”í›ˆ\"\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œ (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n",
        "gt_file_path = '/content/deep-text-recognition-benchmark/data/gt_train.txt'\n",
        "\n",
        "def generate_character_list(file_path):\n",
        "    \"\"\"\n",
        "    ë ˆì´ë¸” íŒŒì¼(gt.txt)ì„ ì½ì–´ ëª¨ë“  ê³ ìœ  ê¸€ìë¥¼ ì¶”ì¶œí•˜ê³ ,\n",
        "    í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” character ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # ê° ì¤„ì—ì„œ íƒ­(\\t)ìœ¼ë¡œ ë¶„ë¦¬ëœ í…ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
        "        labels = [line.strip().split('\\t')[1] for line in lines if '\\t' in line]\n",
        "\n",
        "        # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹œ ë’¤, ê³ ìœ í•œ ê¸€ìë§Œ ì¶”ì¶œ\n",
        "        all_text = \"\".join(labels)\n",
        "        unique_characters = sorted(list(set(all_text)))\n",
        "\n",
        "        # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì— ì‚¬ìš©í•  ìµœì¢… ë¬¸ìì—´ ìƒì„±\n",
        "        character_string = \"\".join(unique_characters)\n",
        "\n",
        "        print(\"âœ… ëª¨ë“  ê³ ìœ  ê¸€ìë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.\")\n",
        "        print(\"-\" * 50)\n",
        "        print(\"ìƒì„±ëœ character ë¬¸ìì—´:\")\n",
        "        print(character_string)\n",
        "        print(\"-\" * 50)\n",
        "        print(\"ğŸ‘‡ ì•„ë˜ì˜ --character ì˜µì…˜ì„ ë³µì‚¬í•˜ì—¬ í•™ìŠµ ëª…ë ¹ì–´ì— ì¶”ê°€í•˜ì„¸ìš”.\")\n",
        "        print(f'--character=\"{character_string}\"')\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"âŒ ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "\n",
        "# í•¨ìˆ˜ ì‹¤í–‰\n",
        "generate_character_list(gt_file_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
